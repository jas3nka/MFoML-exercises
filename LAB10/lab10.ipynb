{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d83c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_pl = spacy.load(\"pl_core_news_lg\")\n",
    "nlp_en = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd3414ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pl.Polish at 0x10ff1e5d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43838021",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_triplets = [\n",
    "    [\"pies\", \"kot\", \"kaktus\"],\n",
    "    [\"samolot\", \"pociąg\", \"kapusta\"],\n",
    "    [\"książka\", \"gazeta\", \"nóż\"],\n",
    "    [\"chleb\", \"masło\", \"telefon\"],\n",
    "    [\"lekarz\", \"pielęgniarka\", \"krzesło\"],\n",
    "    [\"drzewo\", \"krzew\", \"komputer\"],\n",
    "    [\"fortepian\", \"gitara\", \"łyżka\"],\n",
    "    [\"słońce\", \"księżyc\", \"długopis\"],\n",
    "    [\"zupa\", \"makaron\", \"kurtka\"],\n",
    "    [\"mleko\", \"ser\", \"zegarek\"],\n",
    "    [\"łódź\", \"statek\", \"banan\"],\n",
    "    [\"szkoła\", \"uniwersytet\", \"kwiat\"],\n",
    "    [\"dom\", \"mieszkanie\", \"kura\"],\n",
    "    [\"policjant\", \"strażak\", \"pianino\"],\n",
    "    [\"ryba\", \"śledź\", \"krzesło\"],\n",
    "    [\"komórka\", \"smartfon\", \"chmura\"],\n",
    "    [\"śnieg\", \"deszcz\", \"telewizor\"],\n",
    "    [\"rower\", \"hulajnoga\", \"pomidor\"],\n",
    "    [\"jajko\", \"omlet\", \"lampa\"],\n",
    "    [\"koń\", \"osioł\", \"drukarka\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95a5aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Słowa: ['pies', 'kot', 'kaktus']\n",
      "  Similarity between 'pies' and 'kot': 0.8419\n",
      "  Similarity between 'pies' and 'kaktus': 0.3508\n",
      "  Similarity between 'kot' and 'kaktus': 0.4732\n",
      "----------------------------------------\n",
      "Słowa: ['samolot', 'pociąg', 'kapusta']\n",
      "  Similarity between 'samolot' and 'pociąg': 0.5992\n",
      "  Similarity between 'samolot' and 'kapusta': -0.0320\n",
      "  Similarity between 'pociąg' and 'kapusta': -0.0077\n",
      "----------------------------------------\n",
      "Słowa: ['książka', 'gazeta', 'nóż']\n",
      "  Similarity between 'książka' and 'gazeta': 0.5031\n",
      "  Similarity between 'książka' and 'nóż': -0.0178\n",
      "  Similarity between 'gazeta' and 'nóż': -0.0304\n",
      "----------------------------------------\n",
      "Słowa: ['chleb', 'masło', 'telefon']\n",
      "  Similarity between 'chleb' and 'masło': 0.3312\n",
      "  Similarity between 'chleb' and 'telefon': 0.1835\n",
      "  Similarity between 'masło' and 'telefon': 0.0299\n",
      "----------------------------------------\n",
      "Słowa: ['lekarz', 'pielęgniarka', 'krzesło']\n",
      "  Similarity between 'lekarz' and 'pielęgniarka': 0.5162\n",
      "  Similarity between 'lekarz' and 'krzesło': -0.0056\n",
      "  Similarity between 'pielęgniarka' and 'krzesło': 0.1062\n",
      "----------------------------------------\n",
      "Słowa: ['drzewo', 'krzew', 'komputer']\n",
      "  Similarity between 'drzewo' and 'krzew': 0.4587\n",
      "  Similarity between 'drzewo' and 'komputer': 0.0443\n",
      "  Similarity between 'krzew' and 'komputer': 0.1325\n",
      "----------------------------------------\n",
      "Słowa: ['fortepian', 'gitara', 'łyżka']\n",
      "  Similarity between 'fortepian' and 'gitara': 0.4961\n",
      "  Similarity between 'fortepian' and 'łyżka': 0.0419\n",
      "  Similarity between 'gitara' and 'łyżka': 0.2427\n",
      "----------------------------------------\n",
      "Słowa: ['słońce', 'księżyc', 'długopis']\n",
      "  Similarity between 'słońce' and 'księżyc': 0.5478\n",
      "  Similarity between 'słońce' and 'długopis': 0.0142\n",
      "  Similarity between 'księżyc' and 'długopis': 0.1401\n",
      "----------------------------------------\n",
      "Słowa: ['zupa', 'makaron', 'kurtka']\n",
      "  Similarity between 'zupa' and 'makaron': 0.3836\n",
      "  Similarity between 'zupa' and 'kurtka': 0.3300\n",
      "  Similarity between 'makaron' and 'kurtka': 0.0524\n",
      "----------------------------------------\n",
      "Słowa: ['mleko', 'ser', 'zegarek']\n",
      "  Similarity between 'mleko' and 'ser': 0.3324\n",
      "  Similarity between 'mleko' and 'zegarek': -0.0244\n",
      "  Similarity between 'ser' and 'zegarek': 0.2096\n",
      "----------------------------------------\n",
      "Słowa: ['łódź', 'statek', 'banan']\n",
      "  Similarity between 'łódź' and 'statek': 0.3593\n",
      "  Similarity between 'łódź' and 'banan': 0.0624\n",
      "  Similarity between 'statek' and 'banan': 0.1416\n",
      "----------------------------------------\n",
      "Słowa: ['szkoła', 'uniwersytet', 'kwiat']\n",
      "  Similarity between 'szkoła' and 'uniwersytet': 0.3807\n",
      "  Similarity between 'szkoła' and 'kwiat': -0.0825\n",
      "  Similarity between 'uniwersytet' and 'kwiat': 0.1152\n",
      "----------------------------------------\n",
      "Słowa: ['dom', 'mieszkanie', 'kura']\n",
      "  Similarity between 'dom' and 'mieszkanie': 0.4016\n",
      "  Similarity between 'dom' and 'kura': 0.0419\n",
      "  Similarity between 'mieszkanie' and 'kura': -0.0217\n",
      "----------------------------------------\n",
      "Słowa: ['policjant', 'strażak', 'pianino']\n",
      "  Similarity between 'policjant' and 'strażak': 0.6718\n",
      "  Similarity between 'policjant' and 'pianino': -0.0819\n",
      "  Similarity between 'strażak' and 'pianino': -0.0562\n",
      "----------------------------------------\n",
      "Słowa: ['ryba', 'śledź', 'krzesło']\n",
      "  Similarity between 'ryba' and 'śledź': 0.2623\n",
      "  Similarity between 'ryba' and 'krzesło': 0.0211\n",
      "  Similarity between 'śledź' and 'krzesło': -0.0654\n",
      "----------------------------------------\n",
      "Słowa: ['komórka', 'smartfon', 'chmura']\n",
      "  Similarity between 'komórka' and 'smartfon': 0.1762\n",
      "  Similarity between 'komórka' and 'chmura': 0.4026\n",
      "  Similarity between 'smartfon' and 'chmura': 0.1330\n",
      "----------------------------------------\n",
      "Słowa: ['śnieg', 'deszcz', 'telewizor']\n",
      "  Similarity between 'śnieg' and 'deszcz': 0.7936\n",
      "  Similarity between 'śnieg' and 'telewizor': 0.1478\n",
      "  Similarity between 'deszcz' and 'telewizor': 0.1905\n",
      "----------------------------------------\n",
      "Słowa: ['rower', 'hulajnoga', 'pomidor']\n",
      "  Similarity between 'rower' and 'hulajnoga': 0.4734\n",
      "  Similarity between 'rower' and 'pomidor': 0.1487\n",
      "  Similarity between 'hulajnoga' and 'pomidor': 0.0969\n",
      "----------------------------------------\n",
      "Słowa: ['jajko', 'omlet', 'lampa']\n",
      "  Similarity between 'jajko' and 'omlet': 0.4213\n",
      "  Similarity between 'jajko' and 'lampa': 0.0851\n",
      "  Similarity between 'omlet' and 'lampa': -0.0601\n",
      "----------------------------------------\n",
      "Słowa: ['koń', 'osioł', 'drukarka']\n",
      "  Similarity between 'koń' and 'osioł': 0.7359\n",
      "  Similarity between 'koń' and 'drukarka': -0.0671\n",
      "  Similarity between 'osioł' and 'drukarka': -0.0750\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chech which words in triplet are similar to each other\n",
    "for triplet in word_triplets:\n",
    "    print(f\"Słowa: {triplet}\")\n",
    "    for i in range(len(triplet)):\n",
    "        for j in range(i + 1, len(triplet)):\n",
    "            word1 = triplet[i]\n",
    "            word2 = triplet[j]\n",
    "            similarity = nlp_pl(word1).similarity(nlp_pl(word2))\n",
    "            print(f\"  Similarity between '{word1}' and '{word2}': {similarity:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a85878a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'spacy.lexeme.Lexeme'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m wyniki = []\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m slowo_2 \u001b[38;5;129;01min\u001b[39;00m nlp_pl.vocab:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     wektor = \u001b[43mnlp_pl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslowo_2\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].vector\n\u001b[32m     31\u001b[39m     podobienstwo = cosine_similarity(slowo, wektor)\n\u001b[32m     32\u001b[39m     wyniki.append((slowo_2, podobienstwo))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/spacy/language.py:1041\u001b[39m, in \u001b[36mLanguage.__call__\u001b[39m\u001b[34m(self, text, disable, component_cfg)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1022\u001b[39m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1025\u001b[39m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1026\u001b[39m ) -> Doc:\n\u001b[32m   1027\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[32m   1028\u001b[39m \u001b[33;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[32m   1029\u001b[39m \u001b[33;03m    is preserved.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1039\u001b[39m \u001b[33;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m     doc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1043\u001b[39m         component_cfg = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/spacy/language.py:1135\u001b[39m, in \u001b[36mLanguage._ensure_doc\u001b[39m\u001b[34m(self, doc_like)\u001b[39m\n\u001b[32m   1133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m.vocab).from_bytes(doc_like)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E1041.format(\u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[31mValueError\u001b[39m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'spacy.lexeme.Lexeme'>"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "krol = nlp_pl(\"król\")[0].vector\n",
    "mezczyzna = nlp_pl(\"mężczyzna\")[0].vector\n",
    "kobieta = nlp_pl(\"kobieta\")[0].vector\n",
    "\n",
    "slowo = krol - mezczyzna + kobieta\n",
    "\n",
    "slowa = [\"król\", \"mężczyzna\", \"kobieta\", \"królowa\", \"królewna\", \"średniowiecze\", \"królestwo\", \n",
    "        \"monarchia\", \"władca\", \"królewski\", \"korona\", \"tron\", \"dynastia\", \"pałac\", \"koronacja\",\n",
    "        \"piecz\", \"rycerz\", \"wojownik\", \"bitwa\", \"wojna\", \"historia\", \"legendy\",\n",
    "        \"tradycja\", \"kultura\", \"sztuka\", \"literatura\", \"muzyka\", \"tańce\", \"zwyczaje\",\n",
    "        \"miłość\", \"rodzina\", \"dzieci\", \"potomstwo\", \"dziedzictwo\", \"przywództwo\",\n",
    "        \"władza\", \"rząd\", \"polityka\", \"prawo\", \"sprawiedliwość\", \"społeczeństwo\",\n",
    "        \"obywatel\", \"naród\", \"państwo\", \"granice\", \"województwo\", \"miasto\",\n",
    "        \"wieś\", \"osada\", \"gospodarstwo\", \"rolnictwo\", \"przemysł\", \"handel\",\n",
    "        \"gospodarka\", \"ekonomia\", \"finanse\", \"bankowość\", \"inwestycje\", \"biznes\",\n",
    "        \"przedsiębiorstwo\", \"firma\", \"korporacja\", \"praca\", \"zatrudnienie\", \"kariera\",\n",
    "        \"edukacja\", \"nauka\", \"technologia\", \"innowacje\", \"badania\", \"rozwój\",\n",
    "        \"środowisko\", \"ekologia\", \"ochrona\", \"zdrowie\", \"medycyna\", \"choroba\",\n",
    "        \"leczenie\", \"szpital\", \"apteka\", \"lekarstwo\", \"terapia\", \"rehabilitacja\",\n",
    "        \"życie\", \"śmierć\", \"duchowość\", \"religia\", \"wiara\", \"kościół\",\n",
    "        \"świątynia\", \"modlitwa\", \"rytuał\", \"obrzęd\", \"święto\", \"uroczystość\",]\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "wyniki = []\n",
    "for slowo_2 in nlp_pl.vocab:\n",
    "    wektor = nlp_pl(slowo_2)[0].vector\n",
    "    podobienstwo = cosine_similarity(slowo, wektor)\n",
    "    wyniki.append((slowo_2, podobienstwo))\n",
    "\n",
    "wyniki.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Najbardziej podobne słowa do 'król - mężczyzna + kobieta':\")\n",
    "for slowo_2, podobienstwo in wyniki[:5]:\n",
    "    print(f\"Podobieństwo między 'król - mężczyzna + kobieta' a '{slowo_2}': {podobienstwo:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf163ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
